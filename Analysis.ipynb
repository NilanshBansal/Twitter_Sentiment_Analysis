{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC,LinearSVC,NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_reviews = open(\"positive.txt\",\"r\").read()\n",
    "neg_reviews = open(\"negative.txt\",\"r\").read()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for r in pos_reviews.split(\"\\n\"):\n",
    "    documents.append( (r,\"pos\") )\n",
    "    \n",
    "for r in neg_reviews.split(\"\\n\"):\n",
    "    documents.append( (r,\"neg\") )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "\n",
    "pos_words = nltk.word_tokenize(pos_reviews)\n",
    "neg_words = nltk.word_tokenize(neg_reviews)\n",
    "\n",
    "for w in pos_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "\n",
    "for w in neg_words:\n",
    "    all_words.append(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10662"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total no of review sentences\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20321"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total No of Words\n",
    "len(all_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking first 5000 words\n",
    "word_features = list(all_words.keys())[:5000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document,word_features):\n",
    "    words = set(nltk.word_tokenize(document))\n",
    "    \n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)  # Create mapping with True or False if word present -> true\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [ (find_features(rev,word_features),category) for (rev,category) in documents ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10662"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = featuresets[:10000]\n",
    "testing_set = featuresets[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo Accuracy Percent:  71.29909365558912\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Naive Bayes Algo Accuracy Percent: \",(nltk.classify.accuracy(classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              engrossing = True              pos : neg    =     20.9 : 1.0\n",
      "               inventive = True              pos : neg    =     14.3 : 1.0\n",
      "              refreshing = True              pos : neg    =     13.6 : 1.0\n",
      "                    warm = True              pos : neg    =     13.0 : 1.0\n",
      "              disturbing = True              pos : neg    =     12.3 : 1.0\n",
      "               wonderful = True              pos : neg    =     12.2 : 1.0\n",
      "             mesmerizing = True              pos : neg    =     11.6 : 1.0\n",
      "                  beauty = True              pos : neg    =     11.4 : 1.0\n",
      "                provides = True              pos : neg    =     11.4 : 1.0\n",
      "                captures = True              pos : neg    =     11.4 : 1.0\n",
      "            refreshingly = True              pos : neg    =     11.0 : 1.0\n",
      "                powerful = True              pos : neg    =     10.3 : 1.0\n",
      "                    ages = True              pos : neg    =     10.3 : 1.0\n",
      "                  stupid = True              neg : pos    =      9.8 : 1.0\n",
      "                 glimpse = True              pos : neg    =      9.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifier = open(\"naive_bayes.pickle\",\"wb\")\n",
    "pickle.dump(classifier,save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB_classifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB Algo Accuracy Percent:  70.09063444108762\n"
     ]
    }
   ],
   "source": [
    "print(\"MNB Algo Accuracy Percent: \",(nltk.classify.accuracy(MNB_classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving MNB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mnb_classifier = open(\"MNB.pickle\",\"wb\")\n",
    "pickle.dump(MNB_classifier,save_mnb_classifier)\n",
    "save_mnb_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bernoulli_classifier = SklearnClassifier(BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bernoulli_classifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Algo Accuracy Percent:  72.65861027190333\n"
     ]
    }
   ],
   "source": [
    "print(\"Bernoulli Algo Accuracy Percent: \", (nltk.classify.accuracy(Bernoulli_classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bernoulli_classifier = open(\"Bernoulli.pickle\",\"wb\")\n",
    "pickle.dump(Bernoulli_classifier,save_bernoulli_classifier)\n",
    "save_bernoulli_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_classifier = SklearnClassifier(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logistic_classifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Algo Accuracy Percent:  73.41389728096676\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Algo Accuracy Percent: \", (nltk.classify.accuracy(Logistic_classifier,testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Logistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_logistic_classifier = open(\"Logistic.pickle\",\"wb\")\n",
    "pickle.dump(Logistic_classifier,save_logistic_classifier)\n",
    "save_logistic_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
